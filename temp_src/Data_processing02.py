import os
import re
import zipfile
from glob import glob

import numpy as np
import pandas as pd

import matplotlib
import matplotlib.pyplot as plt
import matplotlib.ticker as mticker
import matplotlib.font_manager as fm
import seaborn as sns


# ======================================================================
# ê¸°ë³¸ ì„¤ì •
# ======================================================================

DATA_DIR = "./data/"
PREPROCESSED_DIR = "./preprocessed/"

pd.set_option("display.max_columns", None)
pd.set_option("display.max_colwidth", None)
pd.set_option("display.width", None)


# ======================================================================
# ê³µí†µ ìœ í‹¸ í•¨ìˆ˜
# ======================================================================

def prepare_csv_from_zip(data_dir: str, csv_filename: str, zip_filename: str) -> str:
    """
    data_dir ì•ˆì—ì„œ csv_filename ì´ ì—†ìœ¼ë©´ zip_filename ì„ í’€ì–´ì„œ ìƒì„±í•´ ì£¼ëŠ” í•¨ìˆ˜.
    ìµœì¢…ì ìœ¼ë¡œ csv íŒŒì¼ì˜ ì „ì²´ ê²½ë¡œë¥¼ ë°˜í™˜.
    """
    csv_path = os.path.join(data_dir, csv_filename)
    zip_path = os.path.join(data_dir, zip_filename)

    if not os.path.exists(csv_path):
        print(f"'{csv_path}' is not exist. Checking Zip file.")
        if os.path.exists(zip_path):
            print(f"'{zip_path}' is found. Unzip...")
            try:
                with zipfile.ZipFile(zip_path, "r") as zip_ref:
                    zip_ref.extractall(data_dir)
                print(f"Completed Unzip. '{csv_path}' will be used.")
            except Exception as e:
                print(f"Unzip error: {e}")
                exit()
        else:
            print(f"Error: '{csv_filename}' and '{zip_filename}' are not found.")
            exit()
    return csv_path


# í‘œì¤€ ì—´ ì´ë¦„
COLUMNS_STANDARD = [
    "ë‚ ì§œ", "ê°•ì›", "ê²½ê¸°", "ê²½ë‚¨", "ê²½ë¶", "ê´‘ì£¼", "ëŒ€êµ¬", "ëŒ€ì „",
    "ë¶€ì‚°", "ì„œìš¸", "ì„¸ì¢…", "ìš¸ì‚°", "ì¸ì²œ", "ì „ë‚¨", "ì „ë¶", "ì œì£¼",
    "ì¶©ë‚¨", "ì¶©ë¶",
]

# ì‹œë„ëª… í‘œì¤€í™” ë§¤í•‘
RENAME_MAP = {
    "ìš¸ì‚°ê´‘ì—­ì‹œ": "ìš¸ì‚°",
    "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ": "ì„¸ì¢…",
    "ê²½ê¸°ë„": "ê²½ê¸°",
    "ê°•ì›ë„": "ê°•ì›",
    "ê°•ì›íŠ¹ë³„ìì¹˜ë„": "ê°•ì›",
    "ì¶©ì²­ë¶ë„": "ì¶©ë¶",
    "ì¶©ì²­ë‚¨ë„": "ì¶©ë‚¨",
    "ì „ë¼ë¶ë„": "ì „ë¶",
    "ì „ë¶íŠ¹ë³„ìì¹˜ë„": "ì „ë¶",
    "ì „ë¼ë‚¨ë„": "ì „ë‚¨",
    "ê²½ìƒë¶ë„": "ê²½ë¶",
    "ê²½ìƒë‚¨ë„": "ê²½ë‚¨",
    "ì œì£¼íŠ¹ë³„ìì¹˜ë„": "ì œì£¼",
    "ì œì£¼ë„": "ì œì£¼",
    "ì„œìš¸íŠ¹ë³„ì‹œ": "ì„œìš¸",
    "ë¶€ì‚°ê´‘ì—­ì‹œ": "ë¶€ì‚°",
    "ëŒ€êµ¬ê´‘ì—­ì‹œ": "ëŒ€êµ¬",
    "ì¸ì²œê´‘ì—­ì‹œ": "ì¸ì²œ",
    "ê´‘ì£¼ê´‘ì—­ì‹œ": "ê´‘ì£¼",
    "ëŒ€ì „ê´‘ì—­ì‹œ": "ëŒ€ì „",
    "ì „êµ­": None,      # í•„ìš” ì—†ìœ¼ë©´ ì œê±°
    "ê±°ë˜ì¼": "ë‚ ì§œ",   # ì¼ë¶€ ë°ì´í„°ì—ì„œ 'ê±°ë˜ì¼' â†’ 'ë‚ ì§œ'
}


def standardize_columns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì‹œë„ëª…/ë‚ ì§œ ì—´ ì´ë¦„ì„ RENAME_MAP ê³¼ COLUMNS_STANDARD ê¸°ì¤€ìœ¼ë¡œ ë§ì¶°ì£¼ëŠ” í•¨ìˆ˜.
    """
    df = df.rename(columns=RENAME_MAP).drop(columns=[None], errors="ignore")
    df = df.reindex(columns=COLUMNS_STANDARD)
    return df

def find_file_by_pattern(data_dir: str, pattern: str) -> str:
    """
    data_dir ì•ˆì—ì„œ pattern(*.csv ë“±)ì— ë§¤ì¹­ë˜ëŠ” íŒŒì¼ì„ ì°¾ì•„ì„œ
    í•˜ë‚˜ë§Œ ìˆìœ¼ë©´ ê·¸ ê²½ë¡œë¥¼ ë°˜í™˜.
    ì—†ê±°ë‚˜ ì—¬ëŸ¬ ê°œë©´ ì—ëŸ¬ ë©”ì‹œì§€ ì¶œë ¥ í›„ ì¢…ë£Œ.
    """
    search_pattern = os.path.join(data_dir, pattern)
    matches = glob(search_pattern)

    if len(matches) == 0:
        print(f"[Error] No file matched pattern: {search_pattern}")
        exit()
    elif len(matches) > 1:
        print(f"[Error] Multiple files matched pattern: {search_pattern}")
        for m in matches:
            print(" -", m)
        print("íŒ¨í„´ì— í•˜ë‚˜ë§Œ ë§¤ì¹­ë˜ë„ë¡ íŒŒì¼ëª…ì„ ì •ë¦¬í•´ ì£¼ì„¸ìš”.")
        exit()

    return matches[0]

def reduce_memory_usage(df: pd.DataFrame) -> pd.DataFrame:
    """
    DataFrameì˜ ì»¬ëŸ¼ë“¤ì„ ê°€ëŠ¥í•œ ì‘ì€ dtypeìœ¼ë¡œ ë‹¤ìš´ìºìŠ¤íŒ…í•´ì„œ
    ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ì„ ì¤„ì—¬ì¤Œ.
    """
    start_mem = df.memory_usage().sum() / 1024**2

    for col in df.columns:
        col_type = df[col].dtype

        # ìˆ«ìí˜•ë§Œ ë‹¤ìš´ìºìŠ¤íŠ¸
        if str(col_type)[:3] == 'int':
            df[col] = pd.to_numeric(df[col], downcast='integer')
        elif str(col_type)[:5] == 'float':
            df[col] = pd.to_numeric(df[col], downcast='float')

    end_mem = df.memory_usage().sum() / 1024**2
    print(f"Memory reduced: {start_mem:.3f} MB â†’ {end_mem:.3f} MB")

    return df

# ======================================================================
# 1) ê¸°ì¤€ê¸ˆë¦¬ ë°ì´í„°
# ======================================================================

def load_base_rate(data_dir: str) -> pd.DataFrame:
    # path = os.path.join(data_dir, "*_ê¸°ì¤€ê¸ˆë¦¬.csv")
    path = find_file_by_pattern(data_dir, "*_ê¸°ì¤€ê¸ˆë¦¬.csv")
    rate_csv = pd.read_csv(path, low_memory=False)

    rate_row = rate_csv.iloc[0, 4:]  # ì²« í–‰ì—ì„œ 5ë²ˆì§¸ ì—´ë¶€í„° ë‚ ì§œ êµ¬ê°„ë§Œ
    rate_df = rate_row.reset_index()
    rate_df.columns = ["date", "rate"]

    rate_df["date"] = pd.to_datetime(rate_df["date"])
    rate_df["rate"] = pd.to_numeric(rate_df["rate"], errors="coerce")

    rate_df = rate_df.rename(columns={"date": "ë‚ ì§œ", "rate": "ê¸°ì¤€ê¸ˆë¦¬"})

    print("ê¸°ì¤€ê¸ˆë¦¬ data")
    print(rate_df)

    return rate_df


# ======================================================================
# 2) ì¸êµ¬ìˆ˜ ë°ì´í„°
# ======================================================================

def load_population(data_dir: str) -> pd.DataFrame:
    # path = os.path.join(data_dir, "*_ì¸êµ¬ìˆ˜.csv")
    path = find_file_by_pattern(data_dir, "*_ì¸êµ¬ìˆ˜.csv")

    population_csv = pd.read_csv(
        path,
        encoding="cp949",
        header=[0, 1],
    )

    # ë©€í‹°ì»¬ëŸ¼ ì •ë¦¬
    population_csv.columns = pd.MultiIndex.from_tuples(
        [(str(a).strip(), str(b).strip()) for a, b in population_csv.columns]
    )

    # ì²« ì—´: í–‰ì •êµ¬ì—­
    region = population_csv.iloc[:, 0].astype(str).str.strip()

    # 'ì´ì¸êµ¬ìˆ˜' ì»¬ëŸ¼ë§Œ ì„ íƒ
    data = population_csv.iloc[:, 1:]
    mask_total = data.columns.get_level_values(1).str.contains("ì´ì¸êµ¬ìˆ˜")
    total_only = data.loc[:, mask_total]

    # í–‰ì •êµ¬ì—­ì„ ì¸ë±ìŠ¤ë¡œ
    total_only.index = region

    # ì—´ì˜ 1ë ˆë²¨(ë‚ ì§œ)ë§Œ ì‚¬ìš© â†’ datetime
    dates = total_only.columns.get_level_values(0)
    total_only.columns = pd.to_datetime(dates, format="%Y.%m", errors="coerce")

    # ì „ì¹˜ í›„ ë‚ ì§œë¥¼ ì²« ì»¬ëŸ¼ìœ¼ë¡œ
    population_df = total_only.T.reset_index().rename(columns={"index": "ë‚ ì§œ"})
    population_df.columns.name = "í–‰ì •êµ¬ì—­"

    # ì „êµ­ ì œê±°
    population_df.drop(columns=["ì „êµ­"], inplace=True)

    print("ì¸êµ¬ìˆ˜ data")
    print(population_df)

    return population_df


# ======================================================================
# 3) ì‹¤ì—…ë¥  ë°ì´í„°
# ======================================================================

def load_unemployment(data_dir: str) -> pd.DataFrame:
    # path = os.path.join(data_dir, "*_ì‹¤ì—…ë¥ .csv")
    path = find_file_by_pattern(data_dir, "*_ì‹¤ì—…ë¥ .csv")

    unemployment_csv = pd.read_csv(
        path,
        encoding="cp949",
        header=[0, 1],
    )

    # ë©€í‹°í—¤ë” ì •ë¦¬
    unemployment_csv.columns = pd.MultiIndex.from_tuples(
        [(str(a).strip(), str(b).strip()) for a, b in unemployment_csv.columns]
    )

    # ì²« ë‘ ì»¬ëŸ¼: [ì‹œë„/í–‰ì •êµ¬ì—­], [ì„±ë³„]
    region_col, gender_col = unemployment_csv.columns[0], unemployment_csv.columns[1]
    region = unemployment_csv[region_col].astype(str).str.strip()
    gender = unemployment_csv[gender_col].astype(str).str.strip()

    # ì„±ë³„ == 'ê³„' ë§Œ ì‚¬ìš©
    row_mask = gender == "ê³„"
    region = region[row_mask].replace({"ê³„": "ì „êµ­"})
    df_rows = unemployment_csv.loc[row_mask]

    # ë‚ ì§œ íŒ¨í„´ í•„í„° (YYYY.MM)
    date_pat = re.compile(r"^\d{4}\.\d{2}$")
    col_mask = [
        bool(date_pat.match(a)) for a in df_rows.columns.get_level_values(0)
    ]
    data = df_rows.loc[:, col_mask]

    # 1ë ˆë²¨(ë‚ ì§œ) ê¸°ì¤€ ê·¸ë£¹ â†’ ì²« ì»¬ëŸ¼(ë³´í†µ 'ê³„') ì‚¬ìš©
    data = data.T.groupby(level=0).first().T

    # í–‰ì •êµ¬ì—­ì„ ì¸ë±ìŠ¤ë¡œ, ì—´ì€ datetime
    data.index = region.values
    data.columns = pd.to_datetime(data.columns, format="%Y.%m")

    # ì „ì¹˜í•´ì„œ ë‚ ì§œë¥¼ ì²« ì»¬ëŸ¼ìœ¼ë¡œ
    unemployment_df = data.T.reset_index().rename(columns={"index": "ë‚ ì§œ"})

    # ìˆ«ìí˜• ë³€í™˜
    for c in unemployment_df.columns[1:]:
        unemployment_df[c] = pd.to_numeric(unemployment_df[c], errors="coerce")

    # 2017 ì´ì „ ì„¸ì¢…ì‹œ ì‹¤ì—…ë¥  0ìœ¼ë¡œ ì±„ìš°ê¸°
    if "ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ" in unemployment_df.columns:
        unemployment_df["ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ"] = unemployment_df["ì„¸ì¢…íŠ¹ë³„ìì¹˜ì‹œ"].fillna(0)

    return unemployment_df


# ======================================================================
# 4) ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜(CPI)
# ======================================================================

def load_cpi(data_dir: str) -> pd.DataFrame:
    # path = os.path.join(data_dir, "*_ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜.csv")
    path = find_file_by_pattern(data_dir, "*_ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜.csv")
    price_csv = pd.read_csv(path, encoding="UTF-8-SIG")

    # 0í–‰, 1í–‰ + 5ë²ˆì§¸ ì—´ ì´í›„ (ë‚ ì§œ ì»¬ëŸ¼ë“¤ë§Œ)
    subset = price_csv.iloc[[0, 1], 5:]
    subset.index = ["ì´ì§€ìˆ˜", "ì „ë…„ë™ê¸°ëŒ€ë¹„ì¦ê°ë¥ "]

    cpi_df = subset.T.reset_index()
    cpi_df.columns = ["ë‚ ì§œ", "ì´ì§€ìˆ˜", "ì „ë…„ë™ê¸°ëŒ€ë¹„ì¦ê°ë¥ "]

    cpi_df["ì´ì§€ìˆ˜"] = pd.to_numeric(cpi_df["ì´ì§€ìˆ˜"], errors="coerce")
    cpi_df["ì „ë…„ë™ê¸°ëŒ€ë¹„ì¦ê°ë¥ "] = pd.to_numeric(
        cpi_df["ì „ë…„ë™ê¸°ëŒ€ë¹„ì¦ê°ë¥ "], errors="coerce"
    )

    cpi_df["ë‚ ì§œ"] = pd.to_datetime(
        cpi_df["ë‚ ì§œ"].astype(str),
        errors="coerce",
        format="%Y/%m",
    )

    cpi_df = cpi_df.rename(
        columns={
            "ì´ì§€ìˆ˜": "CPI_ì´ì§€ìˆ˜",
            "ì „ë…„ë™ê¸°ëŒ€ë¹„ì¦ê°ë¥ ": "CPI_ì „ë…„ë™ê¸°",
        }
    )

    print("ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ data")
    print(cpi_df)

    return cpi_df


# ======================================================================
# 5) ê°€ê³„ëŒ€ì¶œê¸ˆ ë°ì´í„°
# ======================================================================

def load_household_loan(data_dir: str) -> pd.DataFrame:
    # ì˜ˆ: ECOS_ê°€ê³„ëŒ€ì¶œ.csv ê°™ì€ ì´ë¦„
    path = find_file_by_pattern(data_dir, "*_ê°€ê³„ëŒ€ì¶œ.csv")

    df = pd.read_csv(path, encoding="UTF-8-SIG")

    # 'ì˜ˆê¸ˆì€í–‰'ë§Œ ì‚¬ìš©
    df = df[df["ê³„ì •í•­ëª©"].str.contains("ì˜ˆê¸ˆì€í–‰", na=False)]

    # ë‚ ì§œ ì»¬ëŸ¼ (ì•ìª½ 5ê°œ ì»¬ëŸ¼ ì´í›„ë¶€í„°ê°€ ë‚ ì§œ)
    date_cols = df.columns[5:]

    melted = df.melt(
        id_vars=["ì§€ì—­ì½”ë“œ"],
        value_vars=date_cols,
        var_name="ë‚ ì§œ",
        value_name="ëŒ€ì¶œê¸ˆì•¡",
    )

    # ë‚ ì§œ ë³€í™˜: "YYYY/MM" â†’ ì›”ì´ˆ ë‚ ì§œ
    melted["ë‚ ì§œ"] = pd.to_datetime(
        melted["ë‚ ì§œ"].astype(str),
        format="%Y/%m",
        errors="coerce",
    ) + pd.offsets.MonthBegin(0)

    # ìˆ«ìí˜• ë³€í™˜
    melted["ëŒ€ì¶œê¸ˆì•¡"] = pd.to_numeric(
        melted["ëŒ€ì¶œê¸ˆì•¡"].astype(str).str.replace(",", ""),
        errors="coerce",
    )

    print("ê°€ê³„ëŒ€ì¶œ data")
    print(melted)

    # ë‚ ì§œ = index, ì§€ì—­ì½”ë“œ = columns
    household_loan_df = (
        melted.pivot_table(
            index="ë‚ ì§œ",
            columns="ì§€ì—­ì½”ë“œ",
            values="ëŒ€ì¶œê¸ˆì•¡",
            aggfunc="first",  # ì¤‘ë³µ ì²˜ë¦¬
        )
        .sort_index()
        .reset_index()
    )

    print("ê°€ê³„ëŒ€ì¶œ pivot data")
    print(household_loan_df)


    return household_loan_df

# ======================================================================
# 6) ì€í—¹ëŒ€ì¶œ ë°ì´í„°
# ======================================================================

def load_bank_loan(data_dir: str) -> pd.DataFrame:
    # path = os.path.join(data_dir, "*_ëŒ€ì¶œê¸ˆ(ë§ì”).csv")
    path = find_file_by_pattern(data_dir, "*_ì€í–‰ëŒ€ì¶œ.csv")

    df = pd.read_csv(path, encoding="UTF-8-SIG", sep='\t')

    # ê³„ì •í•­ëª©ì´ 'ì›í™”ëŒ€ì¶œê¸ˆ' ì¸ í–‰ë§Œ
    df = df[df["ê³„ì •í•­ëª©ë³„"].str.contains("ì›í™”ëŒ€ì¶œê¸ˆ", na=False)]

    date_cols = df.columns[3:]

    melted = df.melt(
        id_vars=["ì§€ì—­ì½”ë“œë³„"],
        value_vars=date_cols,
        var_name="ë‚ ì§œ",
        value_name="ëŒ€ì¶œê¸ˆì•¡",
    )

    melted["ë‚ ì§œ"] = pd.to_datetime(
        melted["ë‚ ì§œ"].astype(str),
        format="%Y.%m",
        errors="coerce",
    ) + pd.offsets.MonthBegin(0)

    bank_loan_df = (
        melted.pivot_table(index="ë‚ ì§œ", columns="ì§€ì—­ì½”ë“œë³„", values="ëŒ€ì¶œê¸ˆì•¡", aggfunc="first")
        .sort_index()
        .reset_index()
    )

    for c in bank_loan_df.columns[1:]:
        bank_loan_df[c] = pd.to_numeric(bank_loan_df[c], errors="coerce")

    print("ì€í—¹ëŒ€ì¶œ data")
    print(bank_loan_df)

    return bank_loan_df

# ======================================================================
# 7) ê°œì¸ì†Œë“ ë°ì´í„°
# ======================================================================

def load_income(data_dir: str) -> pd.DataFrame:
    # path = os.path.join(data_dir, "*_ê°œì¸ì†Œë“.csv")
    path = find_file_by_pattern(data_dir, "*_ê°œì¸ì†Œë“.csv")

    income_csv = pd.read_csv(path, encoding='cp949', header=[0, 1])

    # ë©€í‹°ì»¬ëŸ¼ ì •ë¦¬
    income_csv.columns = pd.MultiIndex.from_tuples(
        [(str(a).strip(), str(b).strip()) for a, b in income_csv.columns]
    )

    regions = income_csv[("ì‹œë„ë³„", "ì‹œë„ë³„")].astype(str).str.strip()

    # '1ì¸ë‹¹ ê°œì¸ì†Œë“' ì»¬ëŸ¼ë§Œ ì‚¬ìš©
    personal_cols = [
        c for c in income_csv.columns if c[1] == "1ì¸ë‹¹ ê°œì¸ì†Œë“"
    ]

    def extract_year(col):
        return int(re.sub(r"[^0-9]", "", col[0]))

    personal_cols = sorted(personal_cols, key=extract_year)

    monthly_list = []

    for col in personal_cols:
        raw_year = col[0]
        year = int(re.sub(r"[^0-9]", "", raw_year))

        annual_income = income_csv[col].astype(float)

        # í•´ë‹¹ ì—°ë„ì˜ ì›”ì´ˆ ë‚ ì§œ 12ê°œ
        dates = pd.date_range(f"{year}-01-01", f"{year}-12-01", freq="MS")
        monthly = pd.DataFrame({"ë‚ ì§œ": dates})

        # ì‹œë„ë³„ë¡œ ì—°ì†Œë“ / 12 / 10 (ë‹¨ìœ„: ë§Œì›)
        for region, value in zip(regions, annual_income):
            monthly[region] = np.round(float(value) / 12 / 10, 1)

        monthly_list.append(monthly)

    income_df = pd.concat(monthly_list, ignore_index=True)

    print("ê°œì¸ì†Œë“ data")
    print(income_df)

    return income_df


# ======================================================================
# 8) ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜ + ìœ„ì¹˜ì½”ë“œ ë°ì´í„° ë¡œë“œ
# ======================================================================

def load_apartment_deal_and_location(data_dir: str):
    deal_csv_path = prepare_csv_from_zip(data_dir, "KoreaApartDeal.csv", "KoreaApartDeal.zip")
    loc_csv_path = prepare_csv_from_zip(data_dir, "LocationCode.csv", "LocationCode.zip")

    try:
        deal_df = pd.read_csv(deal_csv_path, low_memory=False)
        location_df = pd.read_csv(
            loc_csv_path,
            dtype={"ë²•ì •ë™ì½”ë“œ": str, "ìë©´ë™ëª…": str, "ë¦¬ëª…": str},
        )
    except Exception as e:
        print(f"file read error: {e}")
        exit()

    print(f"\n# of Total Raw Data: {len(deal_df):,}")

    # ê±°ë˜ì¼/ê±°ë˜ê¸ˆì•¡ ê²°ì¸¡ ì œê±°
    initial_rows = len(deal_df)
    deal_df.dropna(subset=["ê±°ë˜ì¼", "ê±°ë˜ê¸ˆì•¡"], inplace=True)
    final_rows = len(deal_df)

    # ì‹œêµ°êµ¬ëª… ë§¤í•‘
    location_df_filtered = location_df[location_df["ì‹œêµ°êµ¬ëª…"].notna()].copy()
    location_df_filtered["ì§€ì—­ì½”ë“œ"] = location_df_filtered["ë²•ì •ë™ì½”ë“œ"].str[:5].astype(int)
    loc_map = location_df_filtered[["ì§€ì—­ì½”ë“œ", "ì‹œë„ëª…", "ì‹œêµ°êµ¬ëª…"]].drop_duplicates()

    df = pd.merge(deal_df, loc_map, on="ì§€ì—­ì½”ë“œ", how="left")

    # ë²•ì •ë™ ì½”ë“œ ë§¤í•‘
    loc_lookup = location_df[["ì‹œë„ëª…", "ì‹œêµ°êµ¬ëª…", "ìë©´ë™ëª…", "ë¦¬ëª…", "ë²•ì •ë™ì½”ë“œ"]].copy()
    loc_lookup["ë²•ì •ë™"] = (
        loc_lookup["ìë©´ë™ëª…"].fillna("") + " " + loc_lookup["ë¦¬ëª…"].fillna("")
    ).str.strip()

    final_df = pd.merge(
        df,
        loc_lookup[["ì‹œë„ëª…", "ì‹œêµ°êµ¬ëª…", "ë²•ì •ë™", "ë²•ì •ë™ì½”ë“œ"]],
        on=["ì‹œë„ëª…", "ì‹œêµ°êµ¬ëª…", "ë²•ì •ë™"],
        how="left",
    )

    # UniqueID êµ¬ì„±
    final_df["ì•„íŒŒíŠ¸ID"] = pd.factorize(final_df["ì•„íŒŒíŠ¸"])[0]
    final_df["ì•„íŒŒíŠ¸ID"] = final_df["ì•„íŒŒíŠ¸ID"].astype(str).str.zfill(5)
    final_df["ì „ìš©ë©´ì ID"] = final_df["ì „ìš©ë©´ì "].round(0).astype(int).astype(str).str.zfill(3)
    final_df["UniqueID"] = final_df["ë²•ì •ë™ì½”ë“œ"] + final_df["ì•„íŒŒíŠ¸ID"] + final_df["ì „ìš©ë©´ì ID"]

    # ê±°ë˜ê¸ˆì•¡ ì •ë¦¬
    print("\n--- Cleaning and standardizing the 'ê±°ë˜ê¸ˆì•¡' column ---")
    final_df["ê±°ë˜ê¸ˆì•¡"] = pd.to_numeric(
        final_df["ê±°ë˜ê¸ˆì•¡"].astype(str).str.replace(",", ""),
        errors="coerce",
    )

    # ê±°ë˜ì¼ ì •ë¦¬
    print("\n--- Cleaning and standardizing the 'ê±°ë˜ì¼' column ---")
    final_df["ê±°ë˜ì¼_ì •ë¦¬"] = final_df["ê±°ë˜ì¼"].astype(str).str.split(" ").str[0]
    final_df["ê±°ë˜ì¼_ì •ë¦¬"] = pd.to_datetime(
        final_df["ê±°ë˜ì¼_ì •ë¦¬"],
        format="mixed",
        errors="coerce",
    )

    invalid_dates = final_df[final_df["ê±°ë˜ì¼_ì •ë¦¬"].isnull()]
    if not invalid_dates.empty:
        print("\n[Warning] The following rows could not be converted to a valid date:")
        print(invalid_dates[["ê±°ë˜ì¼"]])

    final_df.dropna(subset=["ê±°ë˜ì¼_ì •ë¦¬"], inplace=True)
    final_df["ê±°ë˜ì¼"] = final_df["ê±°ë˜ì¼_ì •ë¦¬"].dt.date
    final_df.drop(columns=["ê±°ë˜ì¼_ì •ë¦¬"], inplace=True)

    final_columns = [
        "UniqueID", "ì‹œë„ëª…", "ì‹œêµ°êµ¬ëª…", "ë²•ì •ë™", "ì•„íŒŒíŠ¸",
        "ì „ìš©ë©´ì ", "ê±°ë˜ì¼", "ê±°ë˜ê¸ˆì•¡", "ì¸µ", "ê±´ì¶•ë…„ë„",
    ]
    final_columns_exist = [col for col in final_columns if col in final_df.columns]
    final_df = final_df[final_columns_exist]

    # ğŸ”¥ ë‹¤ìš´ìºìŠ¤íŒ… ì ìš©
    final_df = reduce_memory_usage(final_df)

    print("\n'UniqueID' and final:")
    print(final_df)

    return final_df


# ======================================================================
# 8) ì „ì²´ ë¨¸ì§€ íŒŒì´í”„ë¼ì¸
# ======================================================================

def build_apt_price_with_macro():
    # ë§¤í¬ë¡œ ë°ì´í„° ë¡œë“œ
    rate_df = load_base_rate(DATA_DIR)
    population_df = load_population(DATA_DIR)
    unemployment_df = load_unemployment(DATA_DIR)
    cpi_df = load_cpi(DATA_DIR)
    household_loan_df = load_household_loan(DATA_DIR)
    bank_loan_df = load_bank_loan(DATA_DIR)
    income_df = load_income(DATA_DIR)

    # ğŸ”¥ ë‹¤ìš´ìºìŠ¤íŒ…
    rate_df = reduce_memory_usage(rate_df)
    population_df = reduce_memory_usage(population_df)
    unemployment_df = reduce_memory_usage(unemployment_df)
    cpi_df = reduce_memory_usage(cpi_df)
    household_loan_df = reduce_memory_usage(household_loan_df)
    bank_loan_df = reduce_memory_usage(bank_loan_df)
    income_df = reduce_memory_usage(income_df)

    # ì‹œë„ëª…/ì—´ í‘œì¤€í™”
    df1 = standardize_columns(household_loan_df)
    df2 = standardize_columns(population_df)
    df3 = standardize_columns(unemployment_df)
    df6 = standardize_columns(bank_loan_df)
    df7 = standardize_columns(income_df)

    # ë‚ ì§œ í˜•ì‹ í†µì¼
    for df_tmp in [df1, df2, df3, rate_df, cpi_df, df6, df7]:
        df_tmp["ë‚ ì§œ"] = pd.to_datetime(df_tmp["ë‚ ì§œ"], errors="coerce")

    # ì•„íŒŒíŠ¸ ì‹¤ê±°ë˜/ìœ„ì¹˜ ë°ì´í„°
    final_df = load_apartment_deal_and_location(DATA_DIR)

    # ì•„íŒŒíŠ¸ ê°€ê²© DF
    apt_price_df = final_df.copy()

    # ì‹œë„ëª… í‘œì¤€í™” (ê°’ ê¸°ì¤€)
    apt_price_df["ì‹œë„ëª…"] = apt_price_df["ì‹œë„ëª…"].replace(RENAME_MAP)
    apt_price_df = apt_price_df.dropna(subset=["ì‹œë„ëª…"])

    # ê±°ë˜ì¼ datetime ë³€í™˜
    apt_price_df["ê±°ë˜ì¼"] = pd.to_datetime(apt_price_df["ê±°ë˜ì¼"], errors="coerce")
    print(apt_price_df["ê±°ë˜ì¼"].dtype)

    # ê±´ì¶•ë…„ë„ ê²°ì¸¡ ì±„ìš°ê¸°
    apt_price_df["ê±´ì¶•ë…„ë„"] = apt_price_df["ê±´ì¶•ë…„ë„"].fillna(2021)

    # ê¸°ì¤€ê¸ˆë¦¬ asof ë¨¸ì§€
    apt_price_df = pd.merge_asof(
        apt_price_df.sort_values("ê±°ë˜ì¼"),
        rate_df.sort_values("ë‚ ì§œ"),
        left_on="ê±°ë˜ì¼",
        right_on="ë‚ ì§œ",
        direction="forward",
    ).drop(columns=["ë‚ ì§œ"])

    # ê±°ë˜ì¼ì„ ì›”ì´ˆ ê¸°ì¤€ìœ¼ë¡œ (ì›” ë‹¨ìœ„ ë§¤í¬ë¡œì™€ align)
    apt_price_df["ì›”ê¸°ì¤€"] = apt_price_df["ê±°ë˜ì¼"].values.astype("datetime64[M]")
    print(apt_price_df["ê±°ë˜ì¼"].dtype)

    # -------------------------
    # ê°€ê³„ëŒ€ì¶œê¸ˆ í•©ì¹˜ê¸°
    # -------------------------
    print("ê°€ê³„ëŒ€ì¶œê¸ˆ í•©ì¹˜ê¸° start")
    loan_long = df1.melt(
        id_vars=["ë‚ ì§œ"],
        var_name="ì‹œë„ëª…",
        value_name="ê°€ê³„ëŒ€ì¶œ(ë§Œì›)",
    )

    apt_price_df = pd.merge(
        apt_price_df,
        loan_long,
        left_on=["ì›”ê¸°ì¤€", "ì‹œë„ëª…"],
        right_on=["ë‚ ì§œ", "ì‹œë„ëª…"],
        how="left",
    ).drop(columns=["ë‚ ì§œ"])
    print("ê°€ê³„ëŒ€ì¶œê¸ˆ í•©ì¹˜ê¸° end")

    # -------------------------
    # ì€í–‰ëŒ€ì¶œê¸ˆ í•©ì¹˜ê¸°
    # -------------------------
    print("ì€í–‰ëŒ€ì¶œê¸ˆ í•©ì¹˜ê¸° start")
    loan_long = df6.melt(
        id_vars=["ë‚ ì§œ"],
        var_name="ì‹œë„ëª…",
        value_name="ì€í–‰ëŒ€ì¶œ(ë§Œì›)",
    )

    apt_price_df = pd.merge(
        apt_price_df,
        loan_long,
        left_on=["ì›”ê¸°ì¤€", "ì‹œë„ëª…"],
        right_on=["ë‚ ì§œ", "ì‹œë„ëª…"],
        how="left",
    ).drop(columns=["ë‚ ì§œ"])

    print("ì€í–‰ëŒ€ì¶œê¸ˆ í•©ì¹˜ê¸° end")

    # -------------------------
    # ì¸êµ¬ìˆ˜ í•©ì¹˜ê¸°
    # -------------------------
    print("ì¸êµ¬ìˆ˜ í•©ì¹˜ê¸° start")
    pop_long = df2.melt(
        id_vars=["ë‚ ì§œ"],
        var_name="ì‹œë„ëª…",
        value_name="ì¸êµ¬ìˆ˜",
    )

    apt_price_df = pd.merge(
        apt_price_df,
        pop_long,
        left_on=["ì›”ê¸°ì¤€", "ì‹œë„ëª…"],
        right_on=["ë‚ ì§œ", "ì‹œë„ëª…"],
        how="left",
    ).drop(columns=["ë‚ ì§œ"])
    print("ì¸êµ¬ìˆ˜ í•©ì¹˜ê¸° end")

    # -------------------------
    # ì‹¤ì—…ë¥  í•©ì¹˜ê¸°
    # -------------------------
    print("ì‹¤ì—…ë¥  í•©ì¹˜ê¸° start")
    unemp_long = df3.melt(
        id_vars=["ë‚ ì§œ"],
        var_name="ì‹œë„ëª…",
        value_name="ì‹¤ì—…ë¥ ",
    )

    apt_price_df = pd.merge(
        apt_price_df,
        unemp_long,
        left_on=["ì›”ê¸°ì¤€", "ì‹œë„ëª…"],
        right_on=["ë‚ ì§œ", "ì‹œë„ëª…"],
        how="left",
    ).drop(columns=["ë‚ ì§œ"])
    print("ì‹¤ì—…ë¥  í•©ì¹˜ê¸° end")

    # -------------------------
    # CPI (ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜) í•©ì¹˜ê¸°
    # -------------------------
    print("ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ start")
    cpi_df["ì›”ê¸°ì¤€"] = cpi_df["ë‚ ì§œ"].values.astype("datetime64[M]")

    apt_price_df = pd.merge(
        apt_price_df,
        cpi_df,
        on="ì›”ê¸°ì¤€",
        how="left",
    ).drop(columns=["ë‚ ì§œ"])
    print("ì†Œë¹„ìë¬¼ê°€ì§€ìˆ˜ end")

    # -------------------------
    # ê°œì¸ì†Œë“ í•©ì¹˜ê¸°
    # -------------------------
    print("ê°œì¸ì†Œë“ start")
    income_long = df7.melt(
        id_vars=["ë‚ ì§œ"],
        var_name="ì‹œë„ëª…",
        value_name="ì›”ê°œì¸ì†Œë“(ë§Œì›)",
    )

    apt_price_df = pd.merge(
        apt_price_df,
        income_long,
        left_on=["ì›”ê¸°ì¤€", "ì‹œë„ëª…"],
        right_on=["ë‚ ì§œ", "ì‹œë„ëª…"],
        how="left",
    ).drop(columns=["ë‚ ì§œ"])
    print("ê°œì¸ì†Œë“ ê°œì¸ì†Œë“")

    apt_price_df = apt_price_df.drop('ì›”ê¸°ì¤€', axis=1)

    apt_price_df = reduce_memory_usage(apt_price_df)
    
    return apt_price_df


# ======================================================================
# ë©”ì¸ ì‹¤í–‰
# ======================================================================

if __name__ == "__main__":
    apt_price_df = build_apt_price_with_macro()
    print("\n[ì™„ë£Œ] ë§¤í¬ë¡œ ë³€ìˆ˜ê¹Œì§€ í•©ì³ì§„ ì•„íŒŒíŠ¸ ê±°ë˜ ë°ì´í„°:")
    print(apt_price_df.head())

    print("\n writing merged.csv")
    output_path = os.path.join(PREPROCESSED_DIR, "KoreaApartDeal_PreProcessed.csv")
    apt_price_df.to_csv(output_path, index=False)

    print(f"\nCSV written done: {output_path}")
